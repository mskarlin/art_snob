import scrapy
import json
import logging
import sys
import google.cloud.logging
from google.cloud.logging.handlers import CloudLoggingHandler, setup_logging

sys.path.append('../')
sys.path.append('../../')
from utilities.datastore_helpers import DataStoreInterface
from imagemetadata.items import ArtSnobItem
from scrapy.shell import inspect_response
from scrapy.exceptions import CloseSpider


def get_previous_urls(dsi, kind):
    """Query DSI via multiple pages for existing page_urls"""
    cursor = None
    seen_pages = []

    while True:
        logging.info('Querying page of dsi results...')
        items, cursor = dsi.query(kind, n_records=1000, filter_keys=['page_url'], cursor=cursor)
        seen_pages += [v['page_url'] for v in items.values()]
        if cursor is None:
            break

    return set(seen_pages)


class Society6Scraper(scrapy.spiders.SitemapSpider):
    name = "society6"

    sitemap_urls = ["https://society6.com/sitemap/product/framed-prints/framed-prints_1.xml",
                    "https://society6.com/sitemap/product/framed-prints/framed-prints_2.xml"]

    def __init__(self, *args, **kwargs):
        # set up cloud logging for the spider
        client = google.cloud.logging.Client()
        handler = CloudLoggingHandler(client)
        logging.getLogger().setLevel(logging.INFO)  # defaults to WARN
        setup_logging(handler)

        super().__init__(*args, **kwargs)

    def sitemap_filter(self, entries):

        dsi = DataStoreInterface(self.settings.get('GCS_PROJECT'))
        seen_urls = get_previous_urls(dsi, self.settings.get('DATASTORE_KIND'))

        for entry in entries:
            if entry['loc'].split('#')[0] in seen_urls:
                logging.info(f'SKIPPING {entry["loc"]}, already present in database')
                continue
            else:
                yield entry
        else:
            # if we finish everything, and don't yield any items, let's clsoe the spider
            raise StopIteration()
    
    @staticmethod
    def size_price_parse(raw):
        """example: X-Small - 10" X 12"""
        price = raw['price']
        name, size = raw['label'].split(' - ')
        name = name.lower().replace('-', '').replace('(gallery)', '')
        l,h = [int(x.replace('"', '')) for x in size.split(' X ')]
        if l > h:
            name = 'l_'+name
        elif h > l:
            name = 'p_'+name
        
        return {'type': name, 'size': size, 'price': price}

    @staticmethod
    def parse_image(media, image_order):
        link = None
        for key in media:
            for io in image_order:
                if io in media[key]['src']:
                    if media[key]['src'][io] is not None:
                        return media[key]['src'][io]
        return link

    def parse(self, response):
        
        # get the data that we need to parse from JSON generated by JS
        script_raw = response.xpath('//script[contains(text(), "__INITIAL_STATE")]').extract_first()
        json_start = script_raw.find('{')
        json_end = script_raw[::-1].find('}')

        image_order = ['xxl', 'xl', 'lg', 'xs']

        try:
            script_json = json.loads(script_raw[json_start:-json_end])
        except:
            script_json = None

        if script_json:
            # get the tags
            try:
                tags = script_json['product']['response']['product']['data']['attributes']['creative']['tags']
                standard_tags = [t['label'] for t in tags]
            except:
                standard_tags = []
            
            # get the artist
            artist = ''
            try:
                artist = script_json['product']['response']['product']['data']['attributes']['user']['username']
            except:
                pass
            
            # get the prices and sizes (with frames)
            size_price_list = []
            color_list = []
            ao = None
            try: 
                ao = script_json['product']['response']['product']['data']['attributes']['attribute_order']
            except: 
                pass
            
            if ao:
                # grab the colors available for this work
                try: 
                    color_vals = script_json['product']['response']['product']['data']['attributes']['attributes'][ao[0]]['values']
                    color_list = [frames['label'] for n, frames in color_vals.items()]
                except:
                    pass
                
                # grab the size list and price lists
                try: 
                    price_vals = script_json['product']['response']['product']['data']['attributes']['attributes'][ao[1]]['values']
                    size_price_list = [self.size_price_parse(size_price) for n, size_price in price_vals.items()]
                except:
                    pass

            # get the image
            try: 
                media = script_json['product']['response']['product']['data']['attributes']['media_map']
                link = self.parse_image(media, image_order)
            except:
                link = None

        # then we pull data from the html itself
        name = response.xpath('//h1[@id="detailsProductType"]/text()').extract_first()
        # description = response.xpath('//div[@id="product"]').xpath(
        #     '//meta[@itemprop="description"]/@content').extract_first()
        # price = response.xpath('//span[@data-class="retail"]/text()').extract_first()
        # sizes = '|'.join(response.xpath('//div[contains(@class,"ddOption_dropdown_")]/span/text()').extract())

        yield ArtSnobItem(image_urls=[link],
                          page_url=response.url,
                          name=name,
                          description='',
                          size_price_list=size_price_list,
                          color_list=color_list,
                          artist=artist,
                          standard_tags=standard_tags)
