{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,f'{os.getcwd()}/../art_snob_primrose/')\n",
    "from src.datastore_reader import DataStoreReader\n",
    "from src.list_flattener import ListFlattener\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "import pickle\n",
    "import requests\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the features from datastore\n",
    "project='artsnob-1'\n",
    "kind='10232020-pca-nn'\n",
    "\n",
    "dsr = DataStoreReader()\n",
    "entities = dsr.execute(project, kind, max_records=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the features from datastore\n",
    "project='artsnob-1'\n",
    "kind='11202020-tag_reverse_index'\n",
    "\n",
    "dsr = DataStoreReader()\n",
    "ri_entities = dsr.execute(project, kind, max_records=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('10232020-vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(entities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('11202020-reversetag.pkl', 'wb') as f:\n",
    "    pickle.dump(ri_entities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('10232020-vectors.pkl', 'rb') as f:\n",
    "    entities = pickle.load(f)\n",
    "with open('11202020-reversetag.pkl', 'rb') as f:\n",
    "    ri_entities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TODO: let's make some tag embeddings-- we can vectorize with tfidf scores across the tags, then we can \n",
    "    do some pca or umap dim reduction, and concat that vector to see if that helps make the clusters\n",
    "    even better\n",
    "\n",
    "\"\"\"\n",
    "with open('ordered_aids.npy', 'rb') as f:\n",
    "    ordered_aids = np.load(f, allow_pickle=kle=True)\n",
    "    \n",
    "with open('tag_embeddings.npy', 'rb') as f:\n",
    "    tag_embeddings = np.load(f, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_embed_map = dict(zip(ordered_aids, tag_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_embeddings_ordered = np.array([tag_embed_map[k] for k in all_keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = entities['reader_data']\n",
    "ri = ri_entities['reader_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_centroid(tag):\n",
    "    keys = ri[tag]['keys']\n",
    "    vector_lists = [vecs.get(int(key))['umap_data'] for key in keys if int(key) in vecs]\n",
    "    return np.array(vector_lists).mean(axis=0)\n",
    "\n",
    "def close_art(tag, all_art, all_keys):\n",
    "    tc = tag_centroid(tag)\n",
    "    view_art(all_keys[np.argsort(np.abs(all_art - tc).sum(axis=1))[:10]])\n",
    "\n",
    "def dim_extrema(dim=0):\n",
    "    single_dim = np.argsort(all_art[:, dim])\n",
    "    return all_keys[np.concatenate((single_dim[:5], single_dim[-5:]))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_art(dim_extrema(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_art_vectors():\n",
    "    all_art = np.array([v['umap_data'] for k,v in vecs.items()])\n",
    "    all_keys = np.array([k for k,v in vecs.items()])\n",
    "    return all_art, all_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_art(ids):\n",
    "    for idx in ids:\n",
    "        art = requests.get(f'http://localhost:8000/art/{idx}')\n",
    "        print(idx)\n",
    "        display(Image(\"https://storage.googleapis.com/artsnob-image-scrape/\"+art.json()['images'], width=400, height=400))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_art, all_keys = all_art_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_art_tags = np.concatenate((all_art, tag_embeddings_ordered), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = tag_centroid('Digital')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_art('Movies-tv', all_art, all_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Try some umap further dimensional reduction...\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import umap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='white', context='poster', rc={'figure.figsize':(14,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = umap.UMAP(min_dist=0.5, n_neighbors=15, metric='manhattan')\n",
    "u = fit.fit_transform(all_art)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this to use u for all_art rather than the fitted one\n",
    "# prev_u = u\n",
    "u = all_art_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=u[:,0], y=u[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.cluster import Birch, MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from itertools import cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = KDTree(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=100\n",
    "mbk = MiniBatchKMeans(init='k-means++', n_clusters=n_clusters, batch_size=1000,\n",
    "                      n_init=10, max_no_improvement=10, verbose=0,\n",
    "                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all colors that matplotlib provides by default.\n",
    "mbk.fit(u)\n",
    "mbk_means_labels_unique = np.unique(mbk.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## how can we get someone to where they need to be quickest?\n",
    "## do we need to make 10 clusters on top of these clusters? I think so \n",
    "## then we can iterate through those 10, diving into them after the fact \n",
    "\n",
    "## algorithm: iterate through the 10 centroid-based high-level clusters\n",
    "## iterate through likes, then skips, then dislikes\n",
    "high_centroids, high_tree = get_centroids(mbk.cluster_centers_, n_clusters=10)\n",
    "\n",
    "# get the images for each cluster item\n",
    "for hc in high_centroids:\n",
    "    cluster_image(hc, tree, k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the central stuff\n",
    "def get_centroids(data, n_clusters=10):\n",
    "    mbk = MiniBatchKMeans(init='k-means++', n_clusters=n_clusters, batch_size=1000,\n",
    "                          n_init=10, max_no_improvement=10, verbose=0,\n",
    "                          random_state=0)\n",
    "    mbk.fit(data)\n",
    "    tree = KDTree(data)\n",
    "    return mbk.cluster_centers_, tree\n",
    "\n",
    "# get the example from each\n",
    "def cluster_image(this_centroid, tree, k=1):\n",
    "    dist, n_idx = tree.query([this_centroid], k=k)\n",
    "    local_keys = all_keys[n_idx]\n",
    "    view_art(local_keys[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## examples without the umap clustering\n",
    "colors_ = cycle(colors.cnames.keys())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "fig.subplots_adjust(left=0.04, right=0.98, bottom=0.1, top=0.9)\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "for this_centroid, k, col in zip(mbk.cluster_centers_,\n",
    "                                 range(n_clusters), colors_):\n",
    "    \n",
    "    print(f'CLUSTER {k}')\n",
    "    dist, n_idx = tree.query([this_centroid], k=5)\n",
    "    local_keys = all_keys[n_idx]\n",
    "    view_art(local_keys[0])\n",
    "    \n",
    "    mask = mbk.labels_ == k\n",
    "    ax.scatter(u[mask, 0], u[mask, 1], marker='.',\n",
    "               c='w', edgecolor=col, alpha=0.5)\n",
    "    ax.scatter(this_centroid[0], this_centroid[1], marker='+',\n",
    "               c='k', s=25)\n",
    "\n",
    "ax.set_title(\"MiniBatchKMeans\")\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm should start somewhere (can be optimized)\n",
    "# then after dislike, we hurt everything around it with a lower score and move to the unknown place\n",
    "# FIRST let's make a distance matrix\n",
    "cluster_tree = KDTree(mbk.cluster_centers_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_mat = []\n",
    "for c_num, c in enumerate(mbk.cluster_centers_):\n",
    "    dist, n_idx = cluster_tree.query([c], k=len(mbk.cluster_centers_))\n",
    "    dist_map = dict(zip(n_idx[0], dist[0]))\n",
    "    distance_mat.append([dist_map[i] for i in range(len(mbk.cluster_centers_))])\n",
    "\n",
    "distance_mat = np.array(distance_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preference_mask(pos_idx=[], neg_idx=[], size=100):\n",
    "#     blank = np.zeros([size, size])\n",
    "    blank = np.eye(size)\n",
    "    for pid in pos_idx:\n",
    "        blank[pid, :] += np.array([1]*size)\n",
    "        blank[:, pid] += np.array([1]*size).T\n",
    "    for pid in neg_idx:\n",
    "        blank[pid, :] += np.array([1]*size)\n",
    "        blank[:, pid] += np.array([1]*size).T\n",
    "    \n",
    "    return blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = preference_mask([0,1])\n",
    "pos_vals = np.exp(np.multiply(mask, distance_mat)*-0.1).sum(axis=1)\n",
    "neg_mask = preference_mask([], [5,11])\n",
    "neg_vals = -1*np.exp(np.multiply(neg_mask, distance_mat)*-0.1).sum(axis=1)\n",
    "pos_vals + neg_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.multiply(mask, distance_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors_ = cycle(colors.cnames.keys())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "fig.subplots_adjust(left=0.04, right=0.98, bottom=0.1, top=0.9)\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "for this_centroid, k, col in zip(mbk.cluster_centers_,\n",
    "                                 range(n_clusters), colors_):\n",
    "    \n",
    "    print(f'CLUSTER {k}')\n",
    "    dist, n_idx = tree.query([this_centroid], k=5)\n",
    "    local_keys = all_keys[n_idx]\n",
    "    view_art(local_keys[0])\n",
    "    \n",
    "    mask = mbk.labels_ == k\n",
    "    ax.scatter(u[mask, 0], u[mask, 1], marker='.',\n",
    "               c='w', edgecolor=col, alpha=0.5)\n",
    "    ax.scatter(this_centroid[0], this_centroid[1], marker='+',\n",
    "               c='k', s=25)\n",
    "# ax.set_xlim([-25, 25])\n",
    "# ax.set_ylim([-25, 25])\n",
    "ax.set_title(\"MiniBatchKMeans\")\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deco_primrose",
   "language": "python",
   "name": "deco_primrose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
