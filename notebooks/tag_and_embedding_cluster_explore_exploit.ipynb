{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,f'{os.getcwd()}/../art_snob_primrose/')\n",
    "from src.datastore_reader import DataStoreReader\n",
    "from src.list_flattener import ListFlattener\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.cluster import Birch, MiniBatchKMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from itertools import cycle\n",
    "import pickle\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('12012020-distance-cluster-model.pkl', 'rb') as f:\n",
    "    dcm=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the features from datastore\n",
    "project='artsnob-1'\n",
    "kind='frames-scraped-image-data'\n",
    "\n",
    "dsr = DataStoreReader()\n",
    "entities = dsr.execute(project, kind, max_records=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the features from datastore\n",
    "project='artsnob-1'\n",
    "kind='10232020-pca-nn'\n",
    "\n",
    "dsr = DataStoreReader()\n",
    "feat_entities = dsr.execute(project, kind, max_records=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the features from datastore\n",
    "project='artsnob-1'\n",
    "kind='11202020-tag_reverse_index'\n",
    "\n",
    "dsr = DataStoreReader()\n",
    "ri_entities = dsr.execute(project, kind, max_records=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = feat_entities['reader_data']\n",
    "ri = ri_entities['reader_data']\n",
    "data = entities['reader_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aids = []\n",
    "tags = []\n",
    "for aid, entity in data.items():            \n",
    "    tags.append(' '.join(entity['standard_tags']))\n",
    "    aids.append(aid)\n",
    "    \n",
    "tag_data = pd.DataFrame({'aids': aids, 'tags': tags})\n",
    "tag_data['tags'] = tag_data['tags'].map(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_data['tags'] = tag_data['tags'].map(lambda x: x.replace('\\n', '').replace('\\r', '').replace('----', '-').replace('---', '-').replace('--', '-'))\n",
    "vectorizer = TfidfVectorizer(token_pattern=\"(?u)\\\\b[\\\\w-]+\\\\b\", max_features=1000)\n",
    "X = vectorizer.fit_transform(tag_data['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = (X>0).sum(axis=0)\n",
    "sums = X.sum(axis=0)\n",
    "# get average scores and number of items with the tag\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "tags_values = {}\n",
    "for s,c,n in zip((sums/counts).T, counts.T, feature_names):\n",
    "    tags_values[n] = {'score': float(s[0]), 'count': int(c[0])} \n",
    "tag_df = pd.DataFrame().from_dict(tags_values, orient='index')\n",
    "from sklearn import preprocessing\n",
    "tag_df['scaled_score'] = preprocessing.StandardScaler().fit_transform(tag_df['score'].values.reshape(-1, 1))\n",
    "tag_df['scaled_count'] = preprocessing.StandardScaler().fit_transform(np.log(tag_df['count']).values.reshape(-1, 1))\n",
    "tag_df['weighted_score'] = tag_df['scaled_score'] + tag_df['scaled_count'] - (tag_df['count']<500)*5\n",
    "tag_dict = tag_df[['weighted_score', 'score', 'count']].sort_values('weighted_score', ascending=False).to_dict(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.datastore_helpers import DataStoreInterface\n",
    "\n",
    "dsi = DataStoreInterface(project='artsnob-1')\n",
    "ids = []\n",
    "data = []\n",
    "\n",
    "for t, keys in tag_dict.items():\n",
    "    data.append(keys)\n",
    "    ids.append(t)\n",
    "\n",
    "dsi.update(data_list=data, ids=ids, kind='11122020-tag-scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "fullX = X.toarray()\n",
    "feature_fullX = pca.fit_transform(fullX)\n",
    "tag_data['embedding'] = tag_data.index.map(lambda i: feature_fullX[i])\n",
    "ordered_aids = tag_data['aids'].values\n",
    "tag_embeddings = tag_data['embedding'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_art(ids):\n",
    "    for idx in ids:\n",
    "        art = requests.get(f'http://localhost:8000/art/{idx}')\n",
    "        print(idx)\n",
    "        display(Image(\"https://storage.googleapis.com/artsnob-image-scrape/\"+art.json()['images'], width=400, height=400))\n",
    "\n",
    "def all_art_vectors():\n",
    "    all_art = np.array([v['umap_data'] for k,v in vecs.items()])\n",
    "    all_keys = np.array([k for k,v in vecs.items()])\n",
    "    return all_art, all_keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_art, all_keys = all_art_vectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_art_tags = np.concatenate((all_art, tag_embeddings_ordered), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = KDTree(all_art_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=100\n",
    "mbk = MiniBatchKMeans(init='k-means++', n_clusters=n_clusters, batch_size=1000,\n",
    "                      n_init=10, max_no_improvement=10, verbose=0,\n",
    "                      random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all colors that matplotlib provides by default.\n",
    "mbk.fit(u)\n",
    "mbk_means_labels_unique = np.unique(mbk.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of dicts for the inverse index \n",
    "predictions = mbk.predict(u)\n",
    "inverse_cluster_index = []\n",
    "inverse_cluster_keys = []\n",
    "\n",
    "for i, centroid in enumerate(mbk.cluster_centers_):\n",
    "    inverse_cluster_keys.append(i+1)\n",
    "    inverse_cluster_index.append({'centroid': list(centroid), 'idx': [int(ids) for ids in list(all_keys[predictions==i])]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write inverse cluster index to the db\n",
    "from utilities.datastore_helpers import DataStoreInterface\n",
    "dsi = DataStoreInterface(project='artsnob-1')\n",
    "dsi.update(data_list=inverse_cluster_index, ids=inverse_cluster_keys, kind='11292020-inverse-cluster-index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a distance matrix between cluster centers\n",
    "distance_mat = []\n",
    "for c_num, c in enumerate(mbk.cluster_centers_):\n",
    "    dist, n_idx = cluster_tree.query([c], k=len(mbk.cluster_centers_))\n",
    "    dist_map = dict(zip(n_idx[0], dist[0]))\n",
    "    distance_mat.append([dist_map[i] for i in range(len(mbk.cluster_centers_))])\n",
    "\n",
    "distance_mat = np.array(distance_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## examples of clusaters \n",
    "colors_ = cycle(colors.cnames.keys())\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "fig.subplots_adjust(left=0.04, right=0.98, bottom=0.1, top=0.9)\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "for this_centroid, k, col in zip(mbk.cluster_centers_,\n",
    "                                 range(n_clusters), colors_):\n",
    "    \n",
    "    print(f'CLUSTER {k}')\n",
    "    dist, n_idx = tree.query([this_centroid], k=5)\n",
    "    local_keys = all_keys[n_idx]\n",
    "    view_art(local_keys[0])\n",
    "    \n",
    "    mask = mbk.labels_ == k\n",
    "    ax.scatter(all_art_tags[mask, 0], all_art_tags[mask, 1], marker='.',\n",
    "               c='w', edgecolor=col, alpha=0.5)\n",
    "    ax.scatter(this_centroid[0], this_centroid[1], marker='+',\n",
    "               c='k', s=25)\n",
    "\n",
    "ax.set_title(\"MiniBatchKMeans\")\n",
    "ax.set_autoscaley_on(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistanceClusterModel():\n",
    "    \n",
    "    def __init__(self, cluster_centers=None, key_map=None, nn_tree=None, distance_mat=None):\n",
    "        self.cluster_centers = copy.deepcopy(cluster_centers)\n",
    "        self.key_map = copy.deepcopy(key_map)\n",
    "        self.nn_tree = copy.deepcopy(nn_tree)\n",
    "        self.distance_mat = copy.deepcopy(distance_mat)\n",
    "        \n",
    "    def save(self, name='12012020-distance-cluster-model.pkl'):\n",
    "        save_dict = {'cluster_centers': self.cluster_centers, 'key_map': self.key_map,\n",
    "                    'nn_tree': self.nn_tree, 'distance_mat': self.distance_mat}\n",
    "        \n",
    "        with open(name, 'wb') as f:\n",
    "            pickle.dump(save_dict, f)\n",
    "        \n",
    "    def load(self, name):\n",
    "        with open(name, 'rb') as f:\n",
    "            save_dict = pickle.load(f)\n",
    "        \n",
    "        self.cluster_centers = save_dict['cluster_centers']\n",
    "        self.key_map = save_dict['key_map']\n",
    "        self.nn_tree = save_dict['nn_tree']\n",
    "        self.distance_mat = save_dict['distance_mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExploreExploitClusters():\n",
    "    \n",
    "    def __init__(self, distance_cluster_model, alpha=1.0, min_dist=6.0, exp_exl=0.1):\n",
    "        self.cluster_centers = distance_cluster_model.cluster_centers\n",
    "        self.key_map = distance_cluster_model.key_map\n",
    "        self.nn_tree = distance_cluster_model.nn_tree\n",
    "        self.distance_mat = distance_cluster_model.distance_mat\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.min_dist = min_dist\n",
    "        self.exp_exl = exp_exl\n",
    "        self.exponential_drop = self.vectorized_drop()\n",
    "    \n",
    "    def vectorized_drop(self):\n",
    "        f = lambda d: np.exp(max(d, self.min_dist)*-1*self.alpha)\n",
    "        return np.vectorize(f)\n",
    "    \n",
    "    def preference_mask(self, idx=[]):\n",
    "\n",
    "        size = len(self.cluster_centers)\n",
    "        blank = np.zeros([size, size])\n",
    "\n",
    "        for pid in idx:\n",
    "            blank[pid, :] += np.array([1]*size)\n",
    "            blank[:, pid] += np.array([1]*size).T\n",
    "            blank[pid, pid] -= 1\n",
    "\n",
    "        return blank\n",
    "    \n",
    "    def next_item(self, total_mask, likes, skip_n=0):\n",
    "    \n",
    "        masked_exp = np.multiply(exponential_drop(self.distance_mat), total_mask).sum(axis=0)\n",
    "    \n",
    "        if random.random() < self.exp_exl:\n",
    "            print('EXPLOIT')\n",
    "            sorted_mask = np.argsort(-1*masked_exp)\n",
    "            for item in sorted_mask:\n",
    "                if item not in likes:\n",
    "                    if skip_n == 0:\n",
    "                        return item\n",
    "                    else:\n",
    "                        skip_n -= 1\n",
    "        else:\n",
    "            print('EXPLORE')\n",
    "            sorted_mask = np.argsort(np.abs(masked_exp))\n",
    "            for item in sorted_mask:\n",
    "                if item not in likes:\n",
    "                    if skip_n == 0:\n",
    "                        return item\n",
    "                    else:\n",
    "                        skip_n -= 1\n",
    "    \n",
    "    def predict_next(self, likes=[], dislikes=[], skip_n=0, art_ids=True, n_ids=5):\n",
    "        \n",
    "        mask = self.preference_mask(likes)\n",
    "        neg_mask = self.preference_mask(dislikes)\n",
    "        total_mask = mask - neg_mask\n",
    "        \n",
    "        if art_ids:\n",
    "            item = self.next_item(total_mask, likes, skip_n)\n",
    "            dist, n_idx = self.nn_tree.query([self.cluster_centers[item]], k=n_ids)\n",
    "            return item, self.key_map[n_idx][0]\n",
    "        else:\n",
    "            return self.next_item(total_mask, likes, skip_n)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm = DistanceClusterModel(mbk.cluster_centers_, all_keys, tree, distance_mat)\n",
    "eec = ExploreExploitClusters(dcm, exp_exl=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcm.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model here\n",
    "# test teh algorithm\n",
    "\n",
    "cluster, ex_art = eec.predict_next(\n",
    "                                   likes=[0, 38, 33, 94, 69, 36, 39, 75], \n",
    "                                   dislikes=[89, 49, 45, 82, 81, 11, 21, 5, 26], skip_n=0)\n",
    "print(cluster)\n",
    "view_art(ex_art)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deco_primrose",
   "language": "python",
   "name": "deco_primrose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
